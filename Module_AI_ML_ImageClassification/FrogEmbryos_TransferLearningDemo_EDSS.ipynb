{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleunipennings/GOLD_EDSS/blob/main/Module_AI_ML_ImageClassification/FrogEmbryos_TransferLearningDemo_EDSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkzsYI_P_JeN"
      },
      "source": [
        "# Deep Transfer Learning for Biomedical Images\n",
        "\n",
        "*Note: this notebook was created by Dr Ilmi Yoon (Computer Science, SFSU).* \n",
        "\n",
        "*Important: if you want to make changes to this notebook and save these changes, you need to save a copy of the notebook in your own google drive.*\n",
        "\n",
        "In biology and medicine, the task of predicting a condition from image data is important to diagnose a variety of medical conditions, to identify organisms and to do many other things. In computer science, this task is called **image classification**. Algorithmic image classification is usually performed using a specific type of algorithm called **deep learning**. Deep learning is a subset of machine learning. \n",
        "\n",
        "In image classification using deep learning, the workflow usually goes as follows:\n",
        "\n",
        "1. Create a dataset with a folder for each class of image (e.g., dogs in one folder, cats in the other).\n",
        "2. Split this dataset into training, validation, and testing sets.\n",
        "3. Train the model using the training set.\n",
        "4. Optimize the training parameters using the validation set.\n",
        "5. Evaluate the model using the testing set.\n",
        "\n",
        "\n",
        "Deep learning has been successfully used to accurately classify many types of biomedical images. Recently, a classification algorithm was able to detect breast cancer from mammography images with an accuracy of 98% [[1]](https://www.nature.com/articles/s41598-019-48995-4). In collaboration with Dr Ilmi Yoon, Domingo Lab and her graduate students, the accuracy of the classification of images of tadpole (frog) embryos stained with muscle and intersomitic boundaries was improved using deep transfer learning. These images were classified into two categories: control and mutant. This notebook outlines the core algorithm used for this task in a general way, so that future experiments with novel datasets can easily be conducted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnfLdI0jVJwl"
      },
      "source": [
        "## Background\n",
        "\n",
        "Before any code is run, it is important to understand some basics of neural networks and transfer learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g38RYOd_wb9q"
      },
      "source": [
        "### Deep Neural Networks\n",
        "A deep neural network is a conditional probability estimator which can predict the probability of some condition given some input. This makes it useful for image classification, which involves detecting the probability of a condition when provided with an image. This project uses an industry standard neural network architecture called VGG16 (see image), which accepts color images as input and predicts the probability that the image belongs to any of 1000 general image classes. \n",
        "\n",
        "![VGG16 Architecture](https://miro.medium.com/max/470/1*3-TqqkRQ4rWLOMX-gvkYwA.png)\n",
        "\n",
        "\n",
        "This network is composed of many network layers. Each layer further processes the image. The output layer is the orange block at the end of the network, which outputs the probability distribution among the image classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8MivX4hwcNC"
      },
      "source": [
        "### Transfer Learning\n",
        "While Deep Learning has advanced recognition of patterns and understanding of data in various formats, recent advancements in Convolution Neural Network (CNN) achieve super-human level computer vision in natural photo images [3]. Typical human error in image recognition is 5% while the latest CNN models such as VGG19 achieves 3% or lower rates [4]. \n",
        "\n",
        "These achievements are made with advanced Convolution Neural Network (CNN) architecture design, careful selection of hyperparameters, a very large data set (more than 15 million labeled images) and high computation power for long deep learning training; a typical computer science lab will have difficulty in achieving the same results. Fortunately, to promote the advancement of deep learning applications, Google, the Oxford research group or other groups made their fully trained CNN publicly available through “Transfer Learning” technology [4]. \n",
        "\n",
        "Although these fully trained CNN are trained with objects naturally found from photo images such as dog, cat, car, etc., scientists or domain experts have started to use these fully-trained-CNN to classify their scientific data with small additional training process (called fine-tuning).\n",
        "\n",
        "Transfer learning is the process fine-tuning a well trained neural network (like VGG16) for a specific task. This has been proven to be effective at classifying medical image data with minimal training time and smaller datasets than would otherwise be required for high levels of accuracy. The output layer  with 1000 classes is replaced with a custom layer with the number of outputs equal to the number of classes of image we have. In this project, the classes are control and mutant. The network is re-trained with a small hand-labeled dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh9tLaOGFV24"
      },
      "source": [
        "#Getting started "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5p-Y3ncVEzf"
      },
      "source": [
        "### Configuring the Virtual Interpreter\n",
        "The colab environment runs code cells on a virtual cloud computer owned by Google. To ensure that the code is executed efficiently, GPU (graphics processing) must be enabled:\n",
        "\n",
        "* Navigate to 'Runtime' > 'Change Runtime Type'\n",
        "* Set 'Hardware Accelerator' to 'GPU'\n",
        "\n",
        "Once you have performed this step, the output of the code cell below should read 'GPU 0' followed by the name of the graphics processor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OfGhW-ZUG9Q"
      },
      "source": [
        "!nvidia-smi --list-gpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqQejRNKmCGR"
      },
      "source": [
        "### Importing the Software Libraries\n",
        "\n",
        "The following code imports some software libraries necessary to execute the project. We use Numpy, Keras (which is now part of tensorflow), scikit-learn, matplotlib and itertools. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQGet9FW-n55"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import matplotlib.image as mpimg\n",
        "print(\"Import Success!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDrfbG0z_fRP"
      },
      "source": [
        "## 1 - Getting the Data\n",
        "\n",
        "The data must be loaded into the Keras API (a software library) so that it can be easily fed to the machine learning model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cn6KlS01Y1r"
      },
      "source": [
        "### Downloading the Data\n",
        "First, the data must be downloaded to the virtual machine. With this line of code, you are getting the data from my (Pleuni's) google Drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgzGQwrNGOsJ"
      },
      "source": [
        "!gdown --id '1hC_WFptSb_4JSqJG0OAIYyRonpmaslrh' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1ua69_KlXFT"
      },
      "source": [
        "### Extract the Data\n",
        "\n",
        "Since the images are in a .zip file, they must first be extracted to .jpg images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ndA88KR3zY-"
      },
      "source": [
        "!unzip cropdata.zip\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dawVaDuEVyix"
      },
      "source": [
        "## 2 - Splitting the Dataset\n",
        "\n",
        "The data is organised in three folders: train, validation, and test. The training data will be used to train the model. The validation data will be run through the model occationally to ensure that it is generalizing well to input outside the training cases (not overfitting). The validation data is used to determine the optimal amount of training. The test data will not be used until training is completely done in order to measure our peformance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9zS58LoX63h"
      },
      "source": [
        "train_path = 'cropdata/train'\n",
        "valid_path = 'cropdata/valid'\n",
        "test_path = 'cropdata/test'\n",
        "print(\"Paths Loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k60GhdR2fhak"
      },
      "source": [
        "### Creating the Data Generators\n",
        "\n",
        "The model requires the image to be provided as batches of image vectors. By batch, we just mean a consistent number of images. A useful software interface for feeding data into our model is an ImageDataGenerator from the Keras library.  After specifying the data source and other parameters, it will continually generate data batches of specified size for our model to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iojaSuJW-pJw"
      },
      "source": [
        "image_size = (224, 224)\n",
        "classes = ['control', 'mutant']\n",
        "print(\"Training:\")\n",
        "train_batches = ImageDataGenerator() \\\n",
        "                  .flow_from_directory(train_path,\n",
        "                                       image_size,\n",
        "                                       classes=classes,\n",
        "                                       batch_size=15)\n",
        "print(\"Validation:\")\n",
        "valid_batches = ImageDataGenerator() \\\n",
        "                  .flow_from_directory(valid_path,\n",
        "                                       image_size,\n",
        "                                       classes=classes,\n",
        "                                       batch_size=5)\n",
        "print(\"Testing:\")\n",
        "test_batches = ImageDataGenerator() \\\n",
        "                .flow_from_directory(test_path,\n",
        "                                     image_size,\n",
        "                                     classes=classes,\n",
        "                                     batch_size=64,\n",
        "                                     shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Zm0qejfnAX"
      },
      "source": [
        "### Visualizing the Data\n",
        "\n",
        "The following code will display some of the training images so we can see what they look like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXzTJRg83lye"
      },
      "source": [
        "# plots images with labels\n",
        "def plots(ims, figsize=(20,20), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "imgs, labels = next(train_batches)\n",
        "\n",
        "plots(imgs[0:5], titles=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faT60UuDN0sk"
      },
      "source": [
        "## 3 - Creating the Model\n",
        "\n",
        "In Keras, the deep learning model is represented by layers of processing. \n",
        "After importing a pretrained model, a new model is created using this model. All of these layers are copied from the pretrained model to the new model. However, the final output layer will be replaced and retrained using the labeled data, esssentially customizing the output for this specific classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf7o4Ft_hc-d"
      },
      "source": [
        "### Loading a Pretrained Model\n",
        "\n",
        "A pretrained VGG16 model is downloaded using the Keras library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCcMRb_jw5h"
      },
      "source": [
        "vgg16_model = tensorflow.keras.applications.VGG16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n07hpn1fzS0e"
      },
      "source": [
        "vgg16_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUiLZgsPip5k"
      },
      "source": [
        "### Creating a Custom Output Model#\n",
        "\n",
        "A new model is created copying all layers except the output layer. Notice that these layers are set to be non-trainable. Finally, a custom output layer is added to the model.  This output layer should have the same number of outputs as the number of different classes of data. The softmax activation function conditions the output to be a probability distribuiton adding up to unity. \n",
        "In mathematics, the softmax function, also known as softargmax or normalized exponential function, is a function that takes as input a vector of K real numbers, and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers.\n",
        "Therefore, our model will output a probability distribution among the classes as output for each input image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEKi6uvEN0KL"
      },
      "source": [
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "    model.add(layer)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.add(Dense(len(classes), activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI8ljOkmpa0v"
      },
      "source": [
        "### Compiling the Model\n",
        "In preperation for training, the model is compiled. In order to train it, we must evaluate its performance using a loss function. This function is designed to increase as performance decreases. Therefore, in training, we are essentially minimizing the value of the loss function. Since we are predicting a condition (yes/no), we are using cross-entropy, which is a concept from information theory. If we were instead predicting a numerical value, the correct loss function would be 'mean_squared_error'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDG0uQ1qAccz"
      },
      "source": [
        "model.compile(Adam(lr=.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df0KalV7pnmx"
      },
      "source": [
        "## 4 - Training the model by minimizing Loss\n",
        "\n",
        "The model is now trained using the backpropagation algorithm to minimize the loss function. The training data will be passed into the model and evaluated using the loss function. Then, the model will be adjusted to decrease the loss.\n",
        "\n",
        "Here we specifiy the epochs, which is the number of times we pass through the entire training set. These specifications are determined by experimentation with the goal of minimizing validation loss. If the epochs are too high, the model has overfit to the data (too specific). If the epochs are too low, the model has underfit to the data (too general). The validation loss must be compared to training loss to determine if the model is optimally fit to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkFe_2sRpnNt"
      },
      "source": [
        "model.fit(\n",
        "     train_batches,\n",
        "     steps_per_epoch = train_batches.samples // 15,\n",
        "     validation_data = valid_batches, \n",
        "     validation_steps = valid_batches.samples // 5,\n",
        "     epochs=10, \n",
        "     verbose=1)\n",
        "print(\"Trining Complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amJJCzkTOpcF"
      },
      "source": [
        "## 5 - Testing the Model\n",
        "\n",
        "To perform a final test of the model, the test data is fed through the model.  It is important to use data what was removed from the training set so we can test the performance accurately. The accuracy (percentage of images classified correctly) is calculated and a confusion matrix is generated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FK3o1TFt5H9"
      },
      "source": [
        "### Test Accuracy\n",
        "\n",
        "To calculate accuracy, the model is evaluated using the test generator specified earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOKuWUooRcQR"
      },
      "source": [
        "test_batches.samples #print the number of samples in the test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5syFibUt_EA"
      },
      "source": [
        "test_batches = ImageDataGenerator() \\\n",
        "                .flow_from_directory(test_path,\n",
        "                                     image_size,\n",
        "                                     classes=classes,\n",
        "                                     batch_size=189, \n",
        "                                     shuffle=False) # all images in the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_batches,\n",
        "                                     steps=3,\n",
        "                                     verbose=1) \n",
        "print(test_loss)\n",
        "print(test_acc) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOd7ID2uQlc"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "A confusion matrix gives more insight than just accuracy: It indicates which images were classified correctly, and for the incorrect ones, it indicates how (mutant instead of control vs. control instead of mutant). It allows us to determine which classes the model performed well on and which classes the model performed poorly on. If a model performs poorly on a specific class, it may be cauesed by an unclean dataset or insufficient quanitity of images of that class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqGOy1KOs5q"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    \n",
        "test_batches.reset()\n",
        "test_imgs, test_labels = next(test_batches)\n",
        "test_labels = test_labels[:,0]\n",
        "predictions = model.predict(test_batches, steps=1, verbose=0)\n",
        "print(np.round(predictions[:,0]))\n",
        "cm = confusion_matrix(test_labels, np.round(predictions[:,0]))\n",
        "\n",
        "cm_plot_labels = ['control','mutant']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8wUCbpVisU"
      },
      "source": [
        "### Look at the misclassified images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaVcFQulSFC9"
      },
      "source": [
        "labels_pred= np.round(predictions[:,0])\n",
        "falsenegatives = np.where(np.logical_and(test_labels == 1, labels_pred == 0)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siN4PqfI-_Uw"
      },
      "source": [
        "falsenegatives[0][0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejtex20vTMI7"
      },
      "source": [
        "#print(test_labels[0:5])\n",
        "imgs, labels = next(test_batches)\n",
        "\n",
        "plots(imgs[falsenegatives[0][0:5]], titles=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_kfYcqMVyQK"
      },
      "source": [
        "## Preparing for reusing the model later "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBgD03P9O1oq"
      },
      "source": [
        "### Saving the fine-tuned VGG16 model\n",
        "\n",
        "Now that the model has been trained and tested, it should be saved so we can classify new images without retraining."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9xDc240_nCV"
      },
      "source": [
        "model.save('fineTunedVGG16.h5')\n",
        "print(\"Model Saved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNkDKsfRcVS9"
      },
      "source": [
        "### Loading the fine-tuned VGG16 model\n",
        "\n",
        "In a production environment, the model should be loaded without repeating the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4acEqPacdvM"
      },
      "source": [
        "model.load_weights('fineTunedVGG16.h5')\n",
        "print(\"Model Loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNHYAMiphMX_"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we transfer learning for image classification. First, the data is uploaded and connected to the Keras API. Then, the model is defined by copying a pretrained model and adding a new output layer. Once defined, the model can be trained using the appropriate loss function. Finally, the model is evaluated using a test dataset. With minimal modification, the model can be used to predict more than two classes and scalar values. It is encouraged to use this notebook as a templete for similar models using novel datasets. "
      ]
    }
  ]
}